{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618897fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "from collections import deque\n",
    "import itertools\n",
    "\n",
    "import gym\n",
    "from gym.spaces.box import Box\n",
    "from gym import wrappers\n",
    "from gym.wrappers import TransformObservation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from gym.wrappers import RecordVideo, RecordEpisodeStatistics, TimeLimit, AtariPreprocessing\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cb7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRQN(nn.Module):\n",
    "    def __init__(self, state_size , n_actions):\n",
    "        super(DRQN, self).__init__()\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.conv = nn.Sequential(\n",
    "                        nn.Conv2d(state_size[0], 32, 3, stride=2, padding=1),\n",
    "                        nn.ELU(),\n",
    "                        nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "                        nn.ELU(),\n",
    "                        nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "                        nn.ELU(),\n",
    "                        nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "                        nn.ELU()\n",
    "                    )\n",
    "        conv_out_size = self._get_conv_out(state_size)\n",
    "        self.lstm = nn.LSTMCell(conv_out_size, 256)\n",
    "        self.fc_adv = nn.Linear(256, n_actions) \n",
    "        self.fc_value = nn.Linear(256, 1)\n",
    "        \n",
    "    def _get_conv_out(self, shape):\n",
    "        conv_out = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(conv_out.size()))\n",
    "    \n",
    "    def forward(self, x, prev_state=None):        \n",
    "        o = self.conv(x.float()).view(x.shape[0], -1)\n",
    "        if prev_state is not None:\n",
    "            hs, ct = self.lstm(o, prev_state)\n",
    "        else:\n",
    "            hs = torch.zeros(x.shape[0], 256).to(device)\n",
    "            ct = torch.zeros(x.shape[0], 256).to(device)\n",
    "            hs, ct = self.lstm(o)    \n",
    "        \n",
    "        adv = self.fc_adv(hs)\n",
    "        value = self.fc_value(hs)  \n",
    "        return value + adv - torch.mean(adv, dim=1, keepdim=True), (hs, ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91fbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(state, env, net, hidden=None, epsilon=0.0):\n",
    "    if np.random.random() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        state = state.to(device)\n",
    "        q_values, hidden = net(state, hidden)\n",
    "        _, action = torch.max(q_values, dim=1)\n",
    "        action = int(action.item())\n",
    "    return action, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec9d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_deque(buffer, start, stop, step):\n",
    "    buffer.rotate(-start)\n",
    "    slice = list(itertools.islice(buffer, 0, stop-start, step))\n",
    "    buffer.rotate(start)\n",
    "    return slice\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, sample_size, sequence_len):\n",
    "        batch = []\n",
    "        while len(batch) < int(sample_size / 2) :\n",
    "            start = random.randint(0, len(self.buffer) - sequence_len)\n",
    "            sequenze_sample = slice_deque(self.buffer, start, start + sequence_len, 1)\n",
    "            for sample in sequenze_sample:\n",
    "                if sample[1] == 1 or sample[1] == -1:\n",
    "                    batch += sequenze_sample\n",
    "                    \n",
    "        while len(batch) < sample_size:\n",
    "            start = random.randint(0, len(self.buffer) - sequence_len)\n",
    "            sequenze_sample = slice_deque(self.buffer, start, start + sequence_len, 1)\n",
    "            batch += sequenze_sample\n",
    "                    \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c92245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLDataset(IterableDataset):\n",
    "    def __init__(self, buffer, sample_size=400, sequence_len=5):\n",
    "        self.buffer = buffer\n",
    "        self.sample_size = sample_size\n",
    "        self.sequence_len = sequence_len\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for experience in self.buffer.sample(self.sample_size,self.sequence_len):\n",
    "            yield experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb78db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_environment(name):\n",
    "    env = gym.make(name, render_mode=\"rgb_array\")\n",
    "    env.unwrapped._frameskip = 1\n",
    "    env = TimeLimit(env, max_episode_steps=1000)\n",
    "    env = RecordVideo(env, video_folder='./videos/drqn-pong', episode_trigger=lambda x: x % 50 == 0)\n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    env = gym.wrappers.AtariPreprocessing(env, frame_skip=8, noop_max=28, screen_size=64, terminal_on_life_loss=False, grayscale_obs=True, grayscale_newaxis=False, scale_obs=True)\n",
    "    env.observation_space = Box(0.0, 1.0, [1, 64, 64])\n",
    "    return env\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1040f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQLearning(LightningModule):\n",
    "    def __init__(self, env_name, policy=epsilon_greedy, capacity=100_000, \n",
    "               batch_size=256, lr=1e-3, hidden_size=128, gamma=0.99, \n",
    "               loss_fn=nn.MSELoss(), optim=AdamW, eps_start=1.0, eps_end=0.15, \n",
    "               eps_last_episode=400, samples_per_epoch=1024, sync_rate=10,\n",
    "               sequence_length = 8):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.env = create_environment(env_name)\n",
    "\n",
    "        obs_size = self.env.observation_space.shape\n",
    "        n_actions = self.env.action_space.n\n",
    "\n",
    "        self.q_net = DRQN(obs_size, n_actions)\n",
    "\n",
    "        self.target_q_net = copy.deepcopy(self.q_net)\n",
    "\n",
    "        self.policy = policy\n",
    "        self.buffer = ReplayBuffer(capacity=capacity)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        while len(self.buffer) < self.hparams.samples_per_epoch:\n",
    "            print(f\"{len(self.buffer)} samples in experience buffer. Filling...\")\n",
    "            self.play_episode(epsilon=self.hparams.eps_start)\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def play_episode(self, policy=None, epsilon=0.):\n",
    "        state  = self.env.reset()\n",
    "        state  = torch.from_numpy(state[0]).unsqueeze(dim=0)\n",
    "        hidden = None\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            if policy:\n",
    "                action, hidden = policy(state.unsqueeze(dim=0), self.env, self.q_net, hidden, epsilon=epsilon)\n",
    "            else:\n",
    "                action = self.env.action_space.sample()\n",
    "            next_state, reward, done, tru , _ = self.env.step(action)\n",
    "            if tru:\n",
    "                done = tru\n",
    "            \n",
    "            next_state = torch.from_numpy(next_state).unsqueeze(dim=0) \n",
    "            exp = (state, action, reward, done, next_state)\n",
    "            \n",
    "            self.buffer.append(exp)\n",
    "            state = next_state\n",
    "            \n",
    "        self.env.close()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.q_net(x)\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        q_net_optimizer = self.hparams.optim(self.q_net.parameters(), lr=self.hparams.lr)\n",
    "        return [q_net_optimizer]\n",
    "\n",
    "     # Create dataloader.\n",
    "    def train_dataloader(self):\n",
    "        dataset = RLDataset(self.buffer, self.hparams.samples_per_epoch, self.hparams.sequence_length)\n",
    "       \n",
    "        dataloader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=self.hparams.batch_size * self.hparams.sequence_length\n",
    "        )\n",
    "        return dataloader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        states, actions, rewards, dones, next_states = batch\n",
    "        actions = actions.unsqueeze(1)\n",
    "        rewards = rewards.unsqueeze(1)\n",
    "        dones = dones.unsqueeze(1)\n",
    "        \n",
    "        stack_q_values = []\n",
    "        stack_actions = []\n",
    "        stack_rewards = []\n",
    "        stack_dones = []\n",
    "        hidden = None\n",
    "        for i in range(self.hparams.sequence_length):\n",
    "            stack_actions.append(actions[i::self.hparams.sequence_length])\n",
    "            stack_dones.append(dones[i::self.hparams.sequence_length])\n",
    "            stack_rewards.append(rewards[i::self.hparams.sequence_length])\n",
    "            q_values, hidden  = self.q_net(states[i::self.hparams.sequence_length],hidden)\n",
    "            stack_q_values.append(q_values)\n",
    "        stack_q_values = torch.cat(stack_q_values,dim=0)\n",
    "        stack_actions = torch.cat(stack_actions,dim=0)\n",
    "        stack_dones = torch.cat(stack_dones,dim=0)\n",
    "        stack_rewards = torch.cat(stack_rewards,dim=0)\n",
    "\n",
    "    \n",
    "        state_action_values = torch.gather(stack_q_values, -1, stack_actions)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            stack_next_q_values = []\n",
    "            hidden = None\n",
    "            for i in range(self.hparams.sequence_length):\n",
    "                q_values, hidden = self.target_q_net(next_states[i::self.hparams.sequence_length],hidden)\n",
    "                stack_next_q_values.append(q_values)\n",
    "                \n",
    "        stack_next_q_values = torch.cat(stack_next_q_values,dim=0)\n",
    "        next_action_values = torch.max(stack_next_q_values, dim=1)[0].unsqueeze(dim=1)\n",
    "        next_action_values[stack_dones] = 0.0\n",
    "\n",
    "        expected_state_action_values = stack_rewards + self.hparams.gamma * next_action_values\n",
    "        \n",
    "       \n",
    "        loss = self.hparams.loss_fn(state_action_values.float(), expected_state_action_values.float())\n",
    "        self.log('episode/Q-Error', loss)\n",
    "        return loss\n",
    "    \n",
    "    # Training epoch end.\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        epsilon = max(\n",
    "            self.hparams.eps_end,\n",
    "            self.hparams.eps_start - self.current_epoch / self.hparams.eps_last_episode\n",
    "        )\n",
    "\n",
    "        self.play_episode(policy=self.policy, epsilon=epsilon)\n",
    "        self.log('episode/Return', self.env.return_queue[-1])\n",
    "\n",
    "        if self.current_epoch % self.hparams.sync_rate == 0:\n",
    "            self.target_q_net.load_state_dict(self.q_net.state_dict())\n",
    "            \n",
    "            \n",
    "    def save_model(self):\n",
    "        torch.save(self.q_net.state_dict(), \"./model\")\n",
    "        \n",
    "    def load_model(self):\n",
    "        self.q_net.load_state_dict(torch.load( \"./model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5d649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at D:\\multi_agents_rl\\videos\\drqn-pong folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:268: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n",
      "  rank_zero_warn(\n",
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:59: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <TimeLimit<OrderEnforcing<PassiveEnvChecker<AtariEnv<ALE/Pong-v5>>>>> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
      "  logger.warn(\n",
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples in experience buffer. Filling...\n",
      "123 samples in experience buffer. Filling...\n",
      "245 samples in experience buffer. Filling...\n",
      "369 samples in experience buffer. Filling...\n",
      "494 samples in experience buffer. Filling...\n",
      "617 samples in experience buffer. Filling...\n",
      "740 samples in experience buffer. Filling...\n",
      "865 samples in experience buffer. Filling...\n",
      "987 samples in experience buffer. Filling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory D:\\multi_agents_rl\\checkpoints\\drqb-pong exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type | Params\n",
      "--------------------------------------\n",
      "0 | q_net        | DRQN | 818 K \n",
      "1 | target_q_net | DRQN | 818 K \n",
      "--------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.547     Total estimated model params size (MB)\n",
      "D:\\multi_agents_rl\\env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999: : 1it [00:00,  1.42it/s, loss=0.0114, v_num=7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999: : 1it [00:00,  1.38it/s, loss=0.0114, v_num=7]\n"
     ]
    }
   ],
   "source": [
    "algo = DeepQLearning('ALE/Pong-v5')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"./checkpoints/drqb-pong\", save_top_k=1,mode=\"max\", monitor=\"episode/Return\")\n",
    "\n",
    "trainer = Trainer(\n",
    "     accelerator='gpu',\n",
    "     devices=num_gpus,\n",
    "     max_epochs=10_000,\n",
    "     callbacks=[checkpoint_callback], # EarlyStopping(monitor='episode/Return', mode='max', patience=1000)\n",
    ")\n",
    "\n",
    "trainer.fit(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6666ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLay a game with the algorithm\n",
    "env = algo.env\n",
    "policy = algo.policy\n",
    "q_net = algo.q_net.cuda()\n",
    "frames = []\n",
    "\n",
    "for episode in range(10):\n",
    "    state = env.reset()\n",
    "    state = state[0]\n",
    "    state = torch.from_numpy(state).unsqueeze(dim=0)\n",
    "    done = False\n",
    "    hidden = None\n",
    "    while not done:\n",
    "        action, hidden = policy(state, env, q_net, epsilon=0, hidden=hidden)\n",
    "        next_state, reward, done, tru , _ = env.step(action)\n",
    "        next_state = torch.from_numpy(next_state).unsqueeze(dim=0)\n",
    "        if tru:\n",
    "            done = tru\n",
    "        state = next_state\n",
    "        frame = state.squeeze(dim=0)\n",
    "        frame = frame.numpy()\n",
    "        frames.append(frame)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a random game\n",
    "frames = []\n",
    "env = create_environment(\"ALE/Pong-v5\")\n",
    "for episode in range(1):\n",
    "  done = False\n",
    "  obs, _  = env.reset()\n",
    "  while not done:\n",
    "    frames.append(obs)\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, t ,_ = env.step(action)\n",
    "    if t:\n",
    "        done = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10bfb4a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames:\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(frame)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    408\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\IPython\\core\\formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m<decorator-gen-2>:2\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\IPython\\core\\formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\IPython\\core\\pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 151\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\backend_bases.py:2318\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2318\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2320\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pad_inches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2321\u001b[0m             pad_inches \u001b[38;5;241m=\u001b[39m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavefig.pad_inches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\figure.py:1733\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1730\u001b[0m     artists \u001b[38;5;241m=\u001b[39m bbox_extra_artists\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m-> 1733\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1735\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bbox)\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\axes\\_base.py:4422\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4421\u001b[0m locator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_axes_locator()\n\u001b[1;32m-> 4422\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_aspect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlocator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcall_axes_locator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   4426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison \u001b[38;5;129;01mand\u001b[39;00m axis\u001b[38;5;241m.\u001b[39mget_visible():\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\axes\\_base.py:1942\u001b[0m, in \u001b[0;36m_AxesBase.apply_aspect\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m   1940\u001b[0m     pb \u001b[38;5;241m=\u001b[39m position\u001b[38;5;241m.\u001b[39mfrozen()\n\u001b[0;32m   1941\u001b[0m     pb1 \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mshrunk_to_aspect(box_aspect, pb, fig_aspect)\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_position(\u001b[43mpb1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manchored\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_anchor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpb\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1945\u001b[0m \u001b[38;5;66;03m# The following is only seen if self._adjustable == 'datalim'\u001b[39;00m\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\transforms.py:519\u001b[0m, in \u001b[0;36mBboxBase.anchored\u001b[1;34m(self, c, container)\u001b[0m\n\u001b[0;32m    517\u001b[0m     cx, cy \u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    518\u001b[0m L, B, W, H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m             \u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\multi_agents_rl\\env\\lib\\site-packages\\matplotlib\\transforms.py:772\u001b[0m, in \u001b[0;36mBbox.__init__\u001b[1;34m(self, points, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# it is helpful in some contexts to know if the bbox is a\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# default or has been mutated; we store the orig points to\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# support the mutated methods\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_points_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "for frame in frames:\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84ed0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
